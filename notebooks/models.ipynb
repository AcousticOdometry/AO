{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TRorKX0aJrmb"
   },
   "source": [
    "This notebook is part of Andreu's (esdandreu@gmail.com) Master Thesis work at\n",
    "Keio University.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/AcousticOdometry/AO/blob/main/notebooks/models.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C2Q8wXiqTp00"
   },
   "source": [
    "# Setup\n",
    "\n",
    "This section will take care of installing the necessary packages as well as\n",
    "configuring some environment variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colab\n",
    "\n",
    "Assess wether the notebook is being executed in [Google\n",
    "Colab](https://colab.research.google.com/) and if so, set up the software\n",
    "needed in Colab runtime.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Mxqlh9G3n3sF"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "try:\n",
    "    from google import colab\n",
    "    COLAB_RUNTIME = True\n",
    "    %pip install torchinfo\n",
    "    colab.drive.mount('/content/drive')\n",
    "except ImportError:\n",
    "    COLAB_RUNTIME = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JP7gX_G3UrV_"
   },
   "source": [
    "## Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "hFV56apJJicf"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchinfo import summary\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-vDIeFnUup2"
   },
   "source": [
    "### AO\n",
    "\n",
    "Setup Acoustic Odometry python package. If this notebook is being executed in\n",
    "[Colab](#colab), the package will be installed from Github. Because of this, a\n",
    "Github [personal access\n",
    "token](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token)\n",
    "is needed for the installation.\n",
    "\n",
    "If the notebook is not running on Colab and the package is not already\n",
    "installed, installation instructions will be prompted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XZPO4X8roB8k",
    "outputId": "c1fcf943-8933-4af5-89e6-5672e073bd74"
   },
   "outputs": [],
   "source": [
    "if COLAB_RUNTIME:\n",
    "    import subprocess\n",
    "    import requests\n",
    "    import sys\n",
    "    import os\n",
    "    #@markdown Use a [GitHub Personal Access Token](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token)\n",
    "    GITHUB_TOKEN = ''  #@param {type:\"string\"}\n",
    "    auth = requests.auth.HTTPBasicAuth('', GITHUB_TOKEN)\n",
    "    response = requests.get(\n",
    "        \"https://api.github.com/repos/AcousticOdometry/AO/releases/latest\",\n",
    "        auth=auth\n",
    "        )\n",
    "    try:\n",
    "        response.raise_for_status()\n",
    "    except requests.HTTPError as e:\n",
    "        raise RuntimeError(\n",
    "            'Check GITHUB_TOKEN is a Personal Access Token with repo access'\n",
    "            )\n",
    "    headers = {'Accept': 'application/octet-stream'}\n",
    "    for asset in response.json()['assets']:\n",
    "        r = requests.get(\n",
    "            asset['url'], auth=auth, allow_redirects=True, headers=headers\n",
    "            )\n",
    "        r.raise_for_status()\n",
    "        wheel_name = asset['name']\n",
    "        with open(wheel_name, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "        try:\n",
    "            result = subprocess.check_output([\n",
    "                sys.executable, '-m', 'pip', 'install', wheel_name\n",
    "                ])\n",
    "            print(f'Installed {wheel_name}')\n",
    "            break\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            pass\n",
    "        finally:\n",
    "            os.remove(wheel_name)\n",
    "    import ao\n",
    "else:\n",
    "    try:\n",
    "        import ao\n",
    "    except ImportError:\n",
    "        raise ImportError(\n",
    "            \"Acoustic Odometry python extension is not installed. Check \"\n",
    "            r\"https://github.com/AcousticOdometry/AO#readme\"\n",
    "            \" for detailed instructions.\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_folder = Path().parent / 'logs'\n",
    "logging_folder.mkdir(exist_ok=True)\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setLevel(logging.INFO)\n",
    "logging.basicConfig(\n",
    "    format=\"[%(levelname)s] %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\n",
    "            logging_folder / datetime.now().strftime('%Y%m%d_%H%M%S.log')\n",
    "            ),\n",
    "        stream_handler,\n",
    "        ],\n",
    "    level=logging.DEBUG\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import abstractmethod\n",
    "\n",
    "class AcousticOdometryModel(nn.Module):\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "# Reset the subclasses to allow changes without restarting the kernel\n",
    "for subclass in AcousticOdometryModel.__subclasses__():\n",
    "    del subclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNet(AcousticOdometryModel):\n",
    "    def __init__(self, classes: int):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(210816, 512)\n",
    "        self.fc2 = nn.Linear(512, classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        #x = x.view(x.size(0), -1)\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.log_softmax(x,dim=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[__main__.CNNet]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AcousticOdometryModel.__subclasses__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB_RUNTIME:\n",
    "    # @markdown Check where is the experiment folder situated in your drive folder.\n",
    "    # @markdown Remember that if you have been shared the folder, you can\n",
    "    # @markdown [add a shortcut to your drive](https://support.google.com/drive/answer/9700156?hl=en&co=GENIE.Platform%3DDesktop)\n",
    "    # @markdown in order to make it available in google colab.\n",
    "    experiment = \"/content/drive/MyDrive/VAO_WheelTestBed-Experiment-1\"  #@param {type:\"string\"}\n",
    "    EXPERIMENT_FOLDER = Path(experiment)\n",
    "    if not EXPERIMENT_FOLDER.is_dir():\n",
    "        raise RuntimeError(f'Invalid experiment folder {EXPERIMENT_FOLDER}')\n",
    "else:\n",
    "    EXPERIMENT_FOLDER = ao.dataset.utils.get_folder(\n",
    "        env='WHEELTESTBED_EXPERIMENT1'\n",
    "        )\n",
    "DATASETS_FOLDER = EXPERIMENT_FOLDER / 'datasets'\n",
    "MODELS_FOLDER = EXPERIMENT_FOLDER / 'models'\n",
    "MODELS_FOLDER.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Using cuda device\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "logging.info('Using {} device'.format(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(\n",
    "    dataset_folder: Path,\n",
    "    train_split: float = 0.8,\n",
    "    batch_size: int = 15,\n",
    "    ) -> Tuple[Dict[str, torch.utils.data.DataLoader], Dict[str, int]]:\n",
    "    dataset = datasets.DatasetFolder(\n",
    "        root=dataset_folder,\n",
    "        loader=np.load,\n",
    "        extensions=['.npy'],\n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor()\n",
    "            ])\n",
    "        )\n",
    "    train_size = int(train_split * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    loaders = {}\n",
    "    for split, name in zip(\n",
    "        torch.utils.data.random_split(dataset, [train_size, test_size]),\n",
    "        ['train', 'test']\n",
    "        ):\n",
    "        loaders[name] = torch.utils.data.DataLoader(\n",
    "            split,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=2 if DEVICE == 'cuda' else 1,\n",
    "            shuffle=True,\n",
    "            pin_memory=True if DEVICE == 'cuda' else False,\n",
    "            )\n",
    "        logging.info(\n",
    "            f'{name} set: {len(split)} samples, {len(loaders[name])} batches'\n",
    "            )\n",
    "    return loaders, dataset.class_to_idx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "    model: torch.nn.Module,\n",
    "    cost_function: torch.nn.modules.loss._Loss,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    ):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    # TODO use tqdm\n",
    "    for batch_n, (X, Y) in enumerate(dataloader):\n",
    "        X, Y = X.to(DEVICE), Y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(X)\n",
    "        loss = cost_function(prediction, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_n % 100 == 0:\n",
    "            loss, current = loss.item(), batch_n * len(X)\n",
    "            logging.debug(f'loss: {loss:>7f}  [{current:>5d}/{size:>5d}]')\n",
    "\n",
    "\n",
    "def test(\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "    model: torch.nn.Module,\n",
    "    cost_function: torch.nn.modules.loss._Loss,\n",
    "    ):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, Y in dataloader:\n",
    "            X, Y = X.to(DEVICE), Y.to(DEVICE)\n",
    "            pred = model(X)\n",
    "\n",
    "            test_loss += cost_function(pred, Y).item()\n",
    "            correct += (pred.argmax(1) == Y).type(torch.float).sum().item()\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    logging.info(f'acc: {(100*correct):>0.1f}%, avg loss: {test_loss:>8f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    dataset_folder: Path,\n",
    "    model_class: AcousticOdometryModel,\n",
    "    epochs: int = 15,\n",
    "    cost_function: torch.nn.modules.loss._Loss = torch.nn.CrossEntropyLoss(),\n",
    "    optimizer_class: torch.optim.Optimizer = torch.optim.Adam,\n",
    "    optimizer_options: dict = {'lr': 0.001},\n",
    "    ):\n",
    "    loaders, class_to_idx = load_dataset(dataset_folder)\n",
    "    # ! A bit sketchy, in the future the classes should be fixed\n",
    "    model = model_class(classes=len(class_to_idx)).to(DEVICE)\n",
    "    optimizer = optimizer_class(model.parameters(), **optimizer_options)\n",
    "    for t in range(epochs):\n",
    "        logging.info(f'Epoch {t}')\n",
    "        train_epoch(loaders['train'], model, cost_function, optimizer)\n",
    "        test(loaders['test'], model, cost_function)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Couldn't find any class folder in G:\\Shared drives\\VAO [Andreu's Thesis]\\VAO_WheelTestBed-Experiment-1\\datasets\\numpy-arrays.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\esdan\\Desktop\\AO\\notebooks\\models.ipynb Cell 23'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000022?line=0'>1</a>\u001b[0m dataset_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnumpy-arrays\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000022?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m train(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000022?line=2'>3</a>\u001b[0m     dataset_folder\u001b[39m=\u001b[39;49mDATASETS_FOLDER \u001b[39m/\u001b[39;49m dataset_name,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000022?line=3'>4</a>\u001b[0m     model_class\u001b[39m=\u001b[39;49mCNNet,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000022?line=4'>5</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m15\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000022?line=5'>6</a>\u001b[0m     )\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000022?line=6'>7</a>\u001b[0m torch\u001b[39m.\u001b[39msave(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000022?line=7'>8</a>\u001b[0m     model, MODELS_FOLDER \u001b[39m/\u001b[39m (\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000022?line=8'>9</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mname_\u001b[39m\u001b[39m{\u001b[39;00mdataset_name\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m;\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000022?line=9'>10</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mdatetime\u001b[39m.\u001b[39mnow()\u001b[39m.\u001b[39mstrftime(\u001b[39m'\u001b[39m\u001b[39mdate_\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm-\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m;time_\u001b[39m\u001b[39m%\u001b[39m\u001b[39mH-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mM-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mS\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m.pt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000022?line=10'>11</a>\u001b[0m         )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000022?line=11'>12</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000022?line=12'>13</a>\u001b[0m summary(model, input_size\u001b[39m=\u001b[39m(\u001b[39m15\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m256\u001b[39m, \u001b[39m120\u001b[39m))\n",
      "\u001b[1;32mc:\\Users\\esdan\\Desktop\\AO\\notebooks\\models.ipynb Cell 22'\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(dataset_folder, model_class, epochs, cost_function, optimizer_class, optimizer_options)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000021?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000021?line=1'>2</a>\u001b[0m     dataset_folder: Path,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000021?line=2'>3</a>\u001b[0m     model_class: AcousticOdometryModel,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000021?line=6'>7</a>\u001b[0m     optimizer_options: \u001b[39mdict\u001b[39m \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0.001\u001b[39m},\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000021?line=7'>8</a>\u001b[0m     ):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000021?line=8'>9</a>\u001b[0m     loaders, class_to_idx \u001b[39m=\u001b[39m load_dataset(dataset_folder)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000021?line=9'>10</a>\u001b[0m     \u001b[39m# ! A bit sketchy, in the future the classes should be fixed\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000021?line=10'>11</a>\u001b[0m     model \u001b[39m=\u001b[39m model_class(classes\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(class_to_idx))\u001b[39m.\u001b[39mto(DEVICE)\n",
      "\u001b[1;32mc:\\Users\\esdan\\Desktop\\AO\\notebooks\\models.ipynb Cell 19'\u001b[0m in \u001b[0;36mload_dataset\u001b[1;34m(dataset_folder, train_split, batch_size)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000018?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_dataset\u001b[39m(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000018?line=1'>2</a>\u001b[0m     dataset_folder: Path,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000018?line=2'>3</a>\u001b[0m     train_split: \u001b[39mfloat\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0.8\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000018?line=3'>4</a>\u001b[0m     batch_size: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m15\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000018?line=4'>5</a>\u001b[0m     ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Dict[\u001b[39mstr\u001b[39m, torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader], Dict[\u001b[39mstr\u001b[39m, \u001b[39mint\u001b[39m]]:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000018?line=5'>6</a>\u001b[0m     dataset \u001b[39m=\u001b[39m datasets\u001b[39m.\u001b[39;49mDatasetFolder(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000018?line=6'>7</a>\u001b[0m         root\u001b[39m=\u001b[39;49mdataset_folder,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000018?line=7'>8</a>\u001b[0m         loader\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mload,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000018?line=8'>9</a>\u001b[0m         extensions\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39m.npy\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000018?line=9'>10</a>\u001b[0m         transform\u001b[39m=\u001b[39;49mtransforms\u001b[39m.\u001b[39;49mCompose([\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000018?line=10'>11</a>\u001b[0m             transforms\u001b[39m.\u001b[39;49mToTensor()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000018?line=11'>12</a>\u001b[0m             ])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000018?line=12'>13</a>\u001b[0m         )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000018?line=13'>14</a>\u001b[0m     train_size \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(train_split \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(dataset))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000018?line=14'>15</a>\u001b[0m     test_size \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(dataset) \u001b[39m-\u001b[39m train_size\n",
      "File \u001b[1;32mc:\\Users\\esdan\\Desktop\\AO\\venv\\lib\\site-packages\\torchvision\\datasets\\folder.py:145\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/torchvision/datasets/folder.py?line=134'>135</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m    <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/torchvision/datasets/folder.py?line=135'>136</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/torchvision/datasets/folder.py?line=136'>137</a>\u001b[0m     root: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/torchvision/datasets/folder.py?line=141'>142</a>\u001b[0m     is_valid_file: Optional[Callable[[\u001b[39mstr\u001b[39m], \u001b[39mbool\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/torchvision/datasets/folder.py?line=142'>143</a>\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/torchvision/datasets/folder.py?line=143'>144</a>\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(root, transform\u001b[39m=\u001b[39mtransform, target_transform\u001b[39m=\u001b[39mtarget_transform)\n\u001b[1;32m--> <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/torchvision/datasets/folder.py?line=144'>145</a>\u001b[0m     classes, class_to_idx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfind_classes(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot)\n\u001b[0;32m    <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/torchvision/datasets/folder.py?line=145'>146</a>\u001b[0m     samples \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_dataset(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot, class_to_idx, extensions, is_valid_file)\n\u001b[0;32m    <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/torchvision/datasets/folder.py?line=147'>148</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader \u001b[39m=\u001b[39m loader\n",
      "File \u001b[1;32mc:\\Users\\esdan\\Desktop\\AO\\venv\\lib\\site-packages\\torchvision\\datasets\\folder.py:219\u001b[0m, in \u001b[0;36mDatasetFolder.find_classes\u001b[1;34m(self, directory)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/torchvision/datasets/folder.py?line=191'>192</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_classes\u001b[39m(\u001b[39mself\u001b[39m, directory: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[List[\u001b[39mstr\u001b[39m], Dict[\u001b[39mstr\u001b[39m, \u001b[39mint\u001b[39m]]:\n\u001b[0;32m    <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/torchvision/datasets/folder.py?line=192'>193</a>\u001b[0m     \u001b[39m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/torchvision/datasets/folder.py?line=193'>194</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/torchvision/datasets/folder.py?line=194'>195</a>\u001b[0m \u001b[39m        directory/\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/torchvision/datasets/folder.py?line=216'>217</a>\u001b[0m \u001b[39m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/torchvision/datasets/folder.py?line=217'>218</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/torchvision/datasets/folder.py?line=218'>219</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m find_classes(directory)\n",
      "File \u001b[1;32mc:\\Users\\esdan\\Desktop\\AO\\venv\\lib\\site-packages\\torchvision\\datasets\\folder.py:43\u001b[0m, in \u001b[0;36mfind_classes\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/torchvision/datasets/folder.py?line=40'>41</a>\u001b[0m classes \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(entry\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m entry \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mscandir(directory) \u001b[39mif\u001b[39;00m entry\u001b[39m.\u001b[39mis_dir())\n\u001b[0;32m     <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/torchvision/datasets/folder.py?line=41'>42</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m classes:\n\u001b[1;32m---> <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/torchvision/datasets/folder.py?line=42'>43</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find any class folder in \u001b[39m\u001b[39m{\u001b[39;00mdirectory\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/torchvision/datasets/folder.py?line=44'>45</a>\u001b[0m class_to_idx \u001b[39m=\u001b[39m {cls_name: i \u001b[39mfor\u001b[39;00m i, cls_name \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(classes)}\n\u001b[0;32m     <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/torchvision/datasets/folder.py?line=45'>46</a>\u001b[0m \u001b[39mreturn\u001b[39;00m classes, class_to_idx\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Couldn't find any class folder in G:\\Shared drives\\VAO [Andreu's Thesis]\\VAO_WheelTestBed-Experiment-1\\datasets\\numpy-arrays."
     ]
    }
   ],
   "source": [
    "dataset_name = 'numpy-arrays'\n",
    "model = train(\n",
    "    dataset_folder=DATASETS_FOLDER / dataset_name,\n",
    "    model_class=CNNet,\n",
    "    epochs=15,\n",
    "    )\n",
    "torch.save(\n",
    "    model, MODELS_FOLDER / (\n",
    "        f\"name_{dataset_name.replace('_','-')};\" +\n",
    "        f\"{datetime.now().strftime('date_%Y-%m-%d;time_%H-%M-%S')}.pt\"\n",
    "        )\n",
    "    )\n",
    "summary(model, input_size=(15, 1, 256, 120))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b8749b76b3be249eef7e116ab90f03825c0416a2284545ab24c0f7f41fa4add3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
