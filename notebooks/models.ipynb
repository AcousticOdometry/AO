{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TRorKX0aJrmb"
   },
   "source": [
    "This notebook is part of Andreu's (esdandreu@gmail.com) Master Thesis work at\n",
    "Keio University.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/AcousticOdometry/AO/blob/main/notebooks/models.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C2Q8wXiqTp00"
   },
   "source": [
    "# Setup\n",
    "\n",
    "This section will take care of installing the necessary packages as well as\n",
    "configuring some environment variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colab\n",
    "\n",
    "Assess wether the notebook is being executed in [Google\n",
    "Colab](https://colab.research.google.com/) and if so, set up the software\n",
    "needed in Colab runtime.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Mxqlh9G3n3sF"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "try:\n",
    "    from google import colab\n",
    "    COLAB_RUNTIME = True\n",
    "    %pip install torchinfo\n",
    "    colab.drive.mount('/content/drive')\n",
    "except ImportError:\n",
    "    COLAB_RUNTIME = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JP7gX_G3UrV_"
   },
   "source": [
    "## Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hFV56apJJicf"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-vDIeFnUup2"
   },
   "source": [
    "### AO\n",
    "\n",
    "Setup Acoustic Odometry python package. If this notebook is being executed in\n",
    "[Colab](#colab), the package will be installed from Github. Because of this, a\n",
    "Github [personal access\n",
    "token](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token)\n",
    "is needed for the installation.\n",
    "\n",
    "If the notebook is not running on Colab and the package is not already\n",
    "installed, installation instructions will be prompted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XZPO4X8roB8k",
    "outputId": "c1fcf943-8933-4af5-89e6-5672e073bd74"
   },
   "outputs": [],
   "source": [
    "if COLAB_RUNTIME:\n",
    "    import subprocess\n",
    "    import requests\n",
    "    import sys\n",
    "    import os\n",
    "    #@markdown Use a [GitHub Personal Access Token](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token)\n",
    "    GITHUB_TOKEN = ''  #@param {type:\"string\"}\n",
    "    auth = requests.auth.HTTPBasicAuth('', GITHUB_TOKEN)\n",
    "    response = requests.get(\n",
    "        \"https://api.github.com/repos/AcousticOdometry/AO/releases/latest\",\n",
    "        auth=auth\n",
    "        )\n",
    "    try:\n",
    "        response.raise_for_status()\n",
    "    except requests.HTTPError as e:\n",
    "        raise RuntimeError(\n",
    "            'Check GITHUB_TOKEN is a Personal Access Token with repo access'\n",
    "            )\n",
    "    headers = {'Accept': 'application/octet-stream'}\n",
    "    for asset in response.json()['assets']:\n",
    "        r = requests.get(\n",
    "            asset['url'], auth=auth, allow_redirects=True, headers=headers\n",
    "            )\n",
    "        r.raise_for_status()\n",
    "        wheel_name = asset['name']\n",
    "        with open(wheel_name, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "        try:\n",
    "            result = subprocess.check_output([\n",
    "                sys.executable, '-m', 'pip', 'install', wheel_name\n",
    "                ])\n",
    "            print(f'Installed {wheel_name}')\n",
    "            break\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            pass\n",
    "        finally:\n",
    "            os.remove(wheel_name)\n",
    "    import ao\n",
    "else:\n",
    "    try:\n",
    "        import ao\n",
    "    except ImportError:\n",
    "        raise ImportError(\n",
    "            \"Acoustic Odometry python extension is not installed. Check \"\n",
    "            r\"https://github.com/AcousticOdometry/AO#readme\"\n",
    "            \" for detailed instructions.\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_folder = Path().parent / 'logs'\n",
    "logging_folder.mkdir(exist_ok=True)\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setLevel(logging.INFO)\n",
    "logging.basicConfig(\n",
    "    format=\"[%(levelname)s] %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\n",
    "            logging_folder / datetime.now().strftime('%Y%m%d_%H%M%S.log')\n",
    "            ),\n",
    "        stream_handler,\n",
    "        ],\n",
    "    level=logging.DEBUG\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import abstractmethod\n",
    "\n",
    "class AcousticOdometryModel(nn.Module):\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "# Reset the subclasses to allow changes without restarting the kernel\n",
    "for subclass in AcousticOdometryModel.__subclasses__():\n",
    "    del subclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNet(AcousticOdometryModel):\n",
    "    def __init__(self, classes: int):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(210816, 512)\n",
    "        self.fc2 = nn.Linear(512, classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        #x = x.view(x.size(0), -1)\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.log_softmax(x,dim=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[__main__.CNNet]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AcousticOdometryModel.__subclasses__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB_RUNTIME:\n",
    "    # @markdown Check where is the experiment folder situated in your drive folder.\n",
    "    # @markdown Remember that if you have been shared the folder, you can\n",
    "    # @markdown [add a shortcut to your drive](https://support.google.com/drive/answer/9700156?hl=en&co=GENIE.Platform%3DDesktop)\n",
    "    # @markdown in order to make it available in google colab.\n",
    "    experiment = \"/content/drive/MyDrive/VAO_WheelTestBed-Experiment-1\"  #@param {type:\"string\"}\n",
    "    EXPERIMENT_FOLDER = Path(experiment)\n",
    "    if not EXPERIMENT_FOLDER.is_dir():\n",
    "        raise RuntimeError(f'Invalid experiment folder {EXPERIMENT_FOLDER}')\n",
    "else:\n",
    "    EXPERIMENT_FOLDER = ao.dataset.utils.get_folder(\n",
    "        env='WHEELTESTBED_EXPERIMENT1'\n",
    "        )\n",
    "DATASETS_FOLDER = EXPERIMENT_FOLDER / 'datasets'\n",
    "MODELS_FOLDER = EXPERIMENT_FOLDER / 'models'\n",
    "MODELS_FOLDER.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config_from_filesystem(folder: Path) -> dict:\n",
    "    return ao.io.yaml_load(folder / 'dataset.yaml')\n",
    "\n",
    "\n",
    "def get_shards_from_filesystem(folder: Path) -> Dict[str, dict]:\n",
    "    return {\n",
    "        f\"file:{path}\": {\n",
    "            'name': path.name,\n",
    "            **ao.dataset.parse_filename(path.stem)\n",
    "            }\n",
    "        for path in sorted(folder.glob('*.tar'))\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(\n",
    "    dataset_folder: Path,\n",
    "    train_split: float = 0.8,\n",
    "    batch_size: int = 15,\n",
    "    ) -> Tuple[Dict[str, torch.utils.data.DataLoader], Dict[str, int]]:\n",
    "    dataset = datasets.DatasetFolder(\n",
    "        root=dataset_folder,\n",
    "        loader=np.load,\n",
    "        extensions=['.npy'],\n",
    "        )\n",
    "    train_size = int(train_split * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    loaders = {}\n",
    "    for split, name in zip(\n",
    "        torch.utils.data.random_split(dataset, [train_size, test_size]),\n",
    "        ['train', 'test']\n",
    "        ):\n",
    "        loaders[name] = torch.utils.data.DataLoader(\n",
    "            split,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=2 if DEVICE == 'cuda' else 1,\n",
    "            shuffle=True,\n",
    "            pin_memory=True if DEVICE == 'cuda' else False,\n",
    "            )\n",
    "        logging.info(\n",
    "            f'{name} set: {len(split)} samples, {len(loaders[name])} batches'\n",
    "            )\n",
    "    return loaders, dataset.class_to_idx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "    model: torch.nn.Module,\n",
    "    cost_function: torch.nn.modules.loss._Loss,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    ):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    # TODO use tqdm\n",
    "    for batch_n, (X, Y) in enumerate(dataloader):\n",
    "        X, Y = X.float().to(DEVICE), Y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(X)\n",
    "        # logging.debug('Test!')\n",
    "        # logging.debug(prediction)\n",
    "        # logging.debug(Y)\n",
    "        loss = cost_function(prediction, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_n % 100 == 0:\n",
    "            loss, current = loss.item(), batch_n * len(X)\n",
    "            logging.debug(f'loss: {loss:>7f}  [{current:>5d}/{size:>5d}]')\n",
    "\n",
    "\n",
    "def test(\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "    model: torch.nn.Module,\n",
    "    cost_function: torch.nn.modules.loss._Loss,\n",
    "    ):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, Y in dataloader:\n",
    "            X, Y = X.float().to(DEVICE), Y.to(DEVICE)\n",
    "            pred = model(X)\n",
    "\n",
    "            test_loss += cost_function(pred, Y).item()\n",
    "            correct += (pred.argmax(1) == Y).type(torch.float).sum().item()\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    logging.info(f'acc: {(100*correct):>0.1f}%, avg loss: {test_loss:>8f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    dataset_folder: Path,\n",
    "    model_class: AcousticOdometryModel,\n",
    "    epochs: int = 15,\n",
    "    cost_function: torch.nn.modules.loss._Loss = torch.nn.CrossEntropyLoss(),\n",
    "    optimizer_class: torch.optim.Optimizer = torch.optim.Adam,\n",
    "    optimizer_options: dict = {'lr': 0.0001},\n",
    "    ):\n",
    "    loaders, class_to_idx = load_dataset(dataset_folder)\n",
    "    # ! A bit sketchy, in the future the classes should be fixed\n",
    "    model = model_class(classes=len(class_to_idx)).to(DEVICE)\n",
    "    optimizer = optimizer_class(model.parameters(), **optimizer_options)\n",
    "    for t in range(epochs):\n",
    "        logging.info(f'Epoch {t}')\n",
    "        train_epoch(loaders['train'], model, cost_function, optimizer)\n",
    "        test(loaders['test'], model, cost_function)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] train set: 32158 samples, 2144 batches\n",
      "[INFO] test set: 8040 samples, 536 batches\n",
      "[INFO] Epoch 0\n",
      "[INFO] acc: 63.8%, avg loss: 0.071096\n",
      "[INFO] Epoch 1\n",
      "[INFO] acc: 74.1%, avg loss: 0.048939\n",
      "[INFO] Epoch 2\n",
      "[INFO] acc: 81.2%, avg loss: 0.038096\n",
      "[INFO] Epoch 3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\esdan\\Desktop\\AO\\notebooks\\models.ipynb Cell 24\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000023?line=0'>1</a>\u001b[0m dataset_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnew-2-numpy-arrays\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000023?line=1'>2</a>\u001b[0m \u001b[39m# TODO config logging\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000023?line=2'>3</a>\u001b[0m model \u001b[39m=\u001b[39m train(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000023?line=3'>4</a>\u001b[0m     dataset_folder\u001b[39m=\u001b[39;49mDATASETS_FOLDER \u001b[39m/\u001b[39;49m dataset_name,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000023?line=4'>5</a>\u001b[0m     model_class\u001b[39m=\u001b[39;49mCNNet,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000023?line=5'>6</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m15\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000023?line=6'>7</a>\u001b[0m     optimizer_options\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m0.0001\u001b[39;49m},\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000023?line=7'>8</a>\u001b[0m     )\n",
      "\u001b[1;32mc:\\Users\\esdan\\Desktop\\AO\\notebooks\\models.ipynb Cell 24\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(dataset_folder, model_class, epochs, cost_function, optimizer_class, optimizer_options)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000023?line=12'>13</a>\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000023?line=13'>14</a>\u001b[0m     logging\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mt\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000023?line=14'>15</a>\u001b[0m     train_epoch(loaders[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m], model, cost_function, optimizer)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000023?line=15'>16</a>\u001b[0m     test(loaders[\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m], model, cost_function)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000023?line=16'>17</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "\u001b[1;32mc:\\Users\\esdan\\Desktop\\AO\\notebooks\\models.ipynb Cell 24\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(dataloader, model, cost_function, optimizer)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000023?line=7'>8</a>\u001b[0m size \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(dataloader\u001b[39m.\u001b[39mdataset)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000023?line=8'>9</a>\u001b[0m \u001b[39m# TODO use tqdm\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000023?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch_n, (X, Y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000023?line=10'>11</a>\u001b[0m     X, Y \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mto(DEVICE), Y\u001b[39m.\u001b[39mto(DEVICE)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/models.ipynb#ch0000023?line=11'>12</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\esdan\\Desktop\\AO\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    529\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> 530\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    531\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    532\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    533\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    534\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\esdan\\Desktop\\AO\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1207\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1204\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[0;32m   1206\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m-> 1207\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[0;32m   1208\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1209\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[0;32m   1210\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\esdan\\Desktop\\AO\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1163\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1161\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m   1162\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_thread\u001b[39m.\u001b[39mis_alive():\n\u001b[1;32m-> 1163\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[0;32m   1164\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[0;32m   1165\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\esdan\\Desktop\\AO\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1011\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m    999\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1000\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1008\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1009\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1011\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m   1012\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[0;32m   1013\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1014\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1015\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1016\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2800.0_x64__qbz5n2kfra8p0\\lib\\queue.py:179\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[39mif\u001b[39;00m remaining \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m:\n\u001b[0;32m    178\u001b[0m             \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m--> 179\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnot_empty\u001b[39m.\u001b[39;49mwait(remaining)\n\u001b[0;32m    180\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get()\n\u001b[0;32m    181\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnot_full\u001b[39m.\u001b[39mnotify()\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.2800.0_x64__qbz5n2kfra8p0\\lib\\threading.py:306\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    305\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 306\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39;49macquire(\u001b[39mTrue\u001b[39;49;00m, timeout)\n\u001b[0;32m    307\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    308\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39macquire(\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset_name = 'new-2-numpy-arrays'\n",
    "# TODO config logging\n",
    "model = train(\n",
    "    dataset_folder=DATASETS_FOLDER / dataset_name,\n",
    "    model_class=CNNet,\n",
    "    epochs=15,\n",
    "    optimizer_options={'lr': 0.0001},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.jit.save(\n",
    "    model.to_torchscript(), MODELS_FOLDER / (\n",
    "        f\"name_{dataset_name.replace('_','-')};\" +\n",
    "        f\"{datetime.now().strftime('date_%Y-%m-%d;time_%H-%M-%S')}.pt\"\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b8749b76b3be249eef7e116ab90f03825c0416a2284545ab24c0f7f41fa4add3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
