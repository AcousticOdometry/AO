{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TRorKX0aJrmb"
   },
   "source": [
    "This notebook is part of Andreu's (esdandreu@gmail.com) Master Thesis work at\n",
    "Keio University.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/AcousticOdometry/AO/blob/main/notebooks/models.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C2Q8wXiqTp00"
   },
   "source": [
    "# Setup\n",
    "\n",
    "This section will take care of installing the necessary packages as well as\n",
    "configuring some environment variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colab\n",
    "\n",
    "Assess wether the notebook is being executed in [Google\n",
    "Colab](https://colab.research.google.com/) and if so, set up the software\n",
    "needed in Colab runtime.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Mxqlh9G3n3sF"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "try:\n",
    "    from google import colab\n",
    "    COLAB_RUNTIME = True\n",
    "    %pip install torchinfo\n",
    "    colab.drive.mount('/content/drive')\n",
    "except ImportError:\n",
    "    COLAB_RUNTIME = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JP7gX_G3UrV_"
   },
   "source": [
    "## Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hFV56apJJicf"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchinfo import summary\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-vDIeFnUup2"
   },
   "source": [
    "### AO\n",
    "\n",
    "Setup Acoustic Odometry python package. If this notebook is being executed in\n",
    "[Colab](#colab), the package will be installed from Github. Because of this, a\n",
    "Github [personal access\n",
    "token](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token)\n",
    "is needed for the installation.\n",
    "\n",
    "If the notebook is not running on Colab and the package is not already\n",
    "installed, installation instructions will be prompted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XZPO4X8roB8k",
    "outputId": "c1fcf943-8933-4af5-89e6-5672e073bd74"
   },
   "outputs": [],
   "source": [
    "if COLAB_RUNTIME:\n",
    "    import subprocess\n",
    "    import requests\n",
    "    import sys\n",
    "    import os\n",
    "    #@markdown Use a [GitHub Personal Access Token](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token)\n",
    "    GITHUB_TOKEN = ''  #@param {type:\"string\"}\n",
    "    auth = requests.auth.HTTPBasicAuth('', GITHUB_TOKEN)\n",
    "    response = requests.get(\n",
    "        \"https://api.github.com/repos/AcousticOdometry/AO/releases/latest\",\n",
    "        auth=auth\n",
    "        )\n",
    "    try:\n",
    "        response.raise_for_status()\n",
    "    except requests.HTTPError as e:\n",
    "        raise RuntimeError(\n",
    "            'Check GITHUB_TOKEN is a Personal Access Token with repo access'\n",
    "            )\n",
    "    headers = {'Accept': 'application/octet-stream'}\n",
    "    for asset in response.json()['assets']:\n",
    "        r = requests.get(\n",
    "            asset['url'], auth=auth, allow_redirects=True, headers=headers\n",
    "            )\n",
    "        r.raise_for_status()\n",
    "        wheel_name = asset['name']\n",
    "        with open(wheel_name, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "        try:\n",
    "            result = subprocess.check_output([\n",
    "                sys.executable, '-m', 'pip', 'install', wheel_name\n",
    "                ])\n",
    "            print(f'Installed {wheel_name}')\n",
    "            break\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            pass\n",
    "        finally:\n",
    "            os.remove(wheel_name)\n",
    "    import ao\n",
    "else:\n",
    "    try:\n",
    "        import ao\n",
    "    except ImportError:\n",
    "        raise ImportError(\n",
    "            \"Acoustic Odometry python extension is not installed. Check \"\n",
    "            r\"https://github.com/AcousticOdometry/AO#readme\"\n",
    "            \" for detailed instructions.\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_folder = Path().parent / 'logs'\n",
    "logging_folder.mkdir(exist_ok=True)\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setLevel(logging.INFO)\n",
    "logging.basicConfig(\n",
    "    format=\"[%(levelname)s] %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\n",
    "            logging_folder / datetime.now().strftime('%Y%m%d_%H%M%S.log')\n",
    "            ),\n",
    "        stream_handler,\n",
    "        ],\n",
    "    level=logging.DEBUG\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import abstractmethod\n",
    "\n",
    "class AcousticOdometryModel(nn.Module):\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "# Reset the subclasses to allow changes without restarting the kernel\n",
    "for subclass in AcousticOdometryModel.__subclasses__():\n",
    "    del subclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNet(AcousticOdometryModel):\n",
    "    def __init__(self, classes: int):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(210816, 512)\n",
    "        self.fc2 = nn.Linear(512, classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        #x = x.view(x.size(0), -1)\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.log_softmax(x,dim=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[__main__.CNNet]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AcousticOdometryModel.__subclasses__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB_RUNTIME:\n",
    "    # @markdown Check where is the experiment folder situated in your drive folder.\n",
    "    # @markdown Remember that if you have been shared the folder, you can\n",
    "    # @markdown [add a shortcut to your drive](https://support.google.com/drive/answer/9700156?hl=en&co=GENIE.Platform%3DDesktop)\n",
    "    # @markdown in order to make it available in google colab.\n",
    "    experiment = \"/content/drive/MyDrive/VAO_WheelTestBed-Experiment-1\"  #@param {type:\"string\"}\n",
    "    EXPERIMENT_FOLDER = Path(experiment)\n",
    "    if not EXPERIMENT_FOLDER.is_dir():\n",
    "        raise RuntimeError(f'Invalid experiment folder {EXPERIMENT_FOLDER}')\n",
    "else:\n",
    "    EXPERIMENT_FOLDER = ao.dataset.utils.get_folder(\n",
    "        env='WHEELTESTBED_EXPERIMENT1'\n",
    "        )\n",
    "DATASETS_FOLDER = EXPERIMENT_FOLDER / 'datasets'\n",
    "MODELS_FOLDER = EXPERIMENT_FOLDER / 'models'\n",
    "MODELS_FOLDER.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Using cuda device\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(\n",
    "    dataset_folder: Path,\n",
    "    train_split: float = 0.8,\n",
    "    batch_size: int = 15,\n",
    "    ) -> Tuple[Dict[str, torch.utils.data.DataLoader], Dict[str, int]]:\n",
    "    dataset = datasets.DatasetFolder(\n",
    "        root=dataset_folder,\n",
    "        loader=np.load,\n",
    "        extensions=['.npy'],\n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            ])\n",
    "        )\n",
    "    train_size = int(train_split * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    loaders = {}\n",
    "    for split, name in zip(\n",
    "        torch.utils.data.random_split(dataset, [train_size, test_size]),\n",
    "        ['train', 'test']\n",
    "        ):\n",
    "        loaders[name] = torch.utils.data.DataLoader(\n",
    "            split,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=2 if DEVICE == 'cuda' else 1,\n",
    "            shuffle=True,\n",
    "            pin_memory=True if DEVICE == 'cuda' else False,\n",
    "            )\n",
    "        logging.info(\n",
    "            f'{name} set: {len(split)} samples, {len(loaders[name])} batches'\n",
    "            )\n",
    "    return loaders, dataset.class_to_idx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "    model: torch.nn.Module,\n",
    "    cost_function: torch.nn.modules.loss._Loss,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    ):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    # TODO use tqdm\n",
    "    for batch_n, (X, Y) in enumerate(dataloader):\n",
    "        X, Y = X.float().to(DEVICE), Y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(X)\n",
    "        loss = cost_function(prediction, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_n % 100 == 0:\n",
    "            loss, current = loss.item(), batch_n * len(X)\n",
    "            logging.debug(f'loss: {loss:>7f}  [{current:>5d}/{size:>5d}]')\n",
    "\n",
    "\n",
    "def test(\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "    model: torch.nn.Module,\n",
    "    cost_function: torch.nn.modules.loss._Loss,\n",
    "    ):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, Y in dataloader:\n",
    "            X, Y = X.float().to(DEVICE), Y.to(DEVICE)\n",
    "            pred = model(X)\n",
    "\n",
    "            test_loss += cost_function(pred, Y).item()\n",
    "            correct += (pred.argmax(1) == Y).type(torch.float).sum().item()\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    logging.info(f'acc: {(100*correct):>0.1f}%, avg loss: {test_loss:>8f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    dataset_folder: Path,\n",
    "    model_class: AcousticOdometryModel,\n",
    "    epochs: int = 15,\n",
    "    cost_function: torch.nn.modules.loss._Loss = torch.nn.CrossEntropyLoss(),\n",
    "    optimizer_class: torch.optim.Optimizer = torch.optim.Adam,\n",
    "    optimizer_options: dict = {'lr': 0.0001},\n",
    "    ):\n",
    "    loaders, class_to_idx = load_dataset(dataset_folder)\n",
    "    # ! A bit sketchy, in the future the classes should be fixed\n",
    "    model = model_class(classes=len(class_to_idx)).to(DEVICE)\n",
    "    optimizer = optimizer_class(model.parameters(), **optimizer_options)\n",
    "    for t in range(epochs):\n",
    "        logging.info(f'Epoch {t}')\n",
    "        train_epoch(loaders['train'], model, cost_function, optimizer)\n",
    "        test(loaders['test'], model, cost_function)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] train set: 32158 samples, 2144 batches\n",
      "[INFO] test set: 8040 samples, 536 batches\n",
      "[INFO] Epoch 0\n",
      "[INFO] acc: 27.0%, avg loss: 0.104499\n",
      "[INFO] Epoch 1\n",
      "[INFO] acc: 49.0%, avg loss: 0.077143\n",
      "[INFO] Epoch 2\n",
      "[INFO] acc: 78.3%, avg loss: 0.042562\n",
      "[INFO] Epoch 3\n",
      "[INFO] acc: 81.2%, avg loss: 0.034188\n",
      "[INFO] Epoch 4\n",
      "[INFO] acc: 83.5%, avg loss: 0.029783\n",
      "[INFO] Epoch 5\n",
      "[INFO] acc: 84.6%, avg loss: 0.028051\n",
      "[INFO] Epoch 6\n",
      "[INFO] acc: 85.2%, avg loss: 0.026831\n",
      "[INFO] Epoch 7\n",
      "[INFO] acc: 85.3%, avg loss: 0.025986\n",
      "[INFO] Epoch 8\n",
      "[INFO] acc: 86.5%, avg loss: 0.024434\n",
      "[INFO] Epoch 9\n",
      "[INFO] acc: 92.3%, avg loss: 0.017815\n",
      "[INFO] Epoch 10\n",
      "[INFO] acc: 92.2%, avg loss: 0.016778\n",
      "[INFO] Epoch 11\n",
      "[INFO] acc: 92.9%, avg loss: 0.015925\n",
      "[INFO] Epoch 12\n",
      "[INFO] acc: 92.8%, avg loss: 0.015595\n",
      "[INFO] Epoch 13\n",
      "[INFO] acc: 93.1%, avg loss: 0.015481\n",
      "[INFO] Epoch 14\n",
      "[INFO] acc: 93.0%, avg loss: 0.016040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CNNet                                    --                        --\n",
       "├─Conv2d: 1-1                            [15, 64, 252, 116]        1,664\n",
       "├─Conv2d: 1-2                            [15, 128, 122, 54]        204,928\n",
       "├─Dropout2d: 1-3                         [15, 128, 122, 54]        --\n",
       "├─Flatten: 1-4                           [15, 210816]              --\n",
       "├─Linear: 1-5                            [15, 512]                 107,938,304\n",
       "├─Linear: 1-6                            [15, 7]                   3,591\n",
       "==========================================================================================\n",
       "Total params: 108,148,487\n",
       "Trainable params: 108,148,487\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 22.60\n",
       "==========================================================================================\n",
       "Input size (MB): 1.84\n",
       "Forward/backward pass size (MB): 325.76\n",
       "Params size (MB): 432.59\n",
       "Estimated Total Size (MB): 760.19\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = 'numpy-arrays'\n",
    "# TODO config logging\n",
    "model = train(\n",
    "    dataset_folder=DATASETS_FOLDER / dataset_name,\n",
    "    model_class=CNNet,\n",
    "    epochs=15,\n",
    "    optimizer_options={'lr': 0.0001},\n",
    "    )\n",
    "torch.save(\n",
    "    model, MODELS_FOLDER / (\n",
    "        f\"name_{dataset_name.replace('_','-')};\" +\n",
    "        f\"{datetime.now().strftime('date_%Y-%m-%d;time_%H-%M-%S')}.pt\"\n",
    "        )\n",
    "    )\n",
    "# TODO close logging and copy to MODELS FOLDER\n",
    "summary(model, input_size=(15, 1, 256, 120))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b8749b76b3be249eef7e116ab90f03825c0416a2284545ab24c0f7f41fa4add3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
