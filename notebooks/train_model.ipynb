{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TRorKX0aJrmb"
   },
   "source": [
    "This notebook is part of Andreu's (esdandreu@gmail.com) Master Thesis work at\n",
    "Keio University.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/AcousticOdometry/AO/blob/main/notebooks/plot_features.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C2Q8wXiqTp00"
   },
   "source": [
    "# Setup\n",
    "This section will take care of installing the necessary packages as well as\n",
    "configuring some environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLAB_RUNTIME = False\n",
    "GITHUB_TOKEN = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colab\n",
    "Assess wether the notebook is being executed in [Google\n",
    "Colab](https://colab.research.google.com/) and if so, set up the software\n",
    "needed in Colab runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Mxqlh9G3n3sF"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "try:\n",
    "    import colab\n",
    "    COLAB_RUNTIME = True\n",
    "    # Check CMake >= 3.21\n",
    "    v_str, *_ = !cmake --version\n",
    "    if 'command not found' in v_str:\n",
    "        major, minor = (0, 0)\n",
    "    else:\n",
    "        major, minor, _ = (int(x) for x in v_str.split(' ')[-1].split('.'))\n",
    "    if major < 3 or minor < 21:\n",
    "        # https://cmake.org/download/\n",
    "        %cd /tmp\n",
    "        !wget https://github.com/Kitware/CMake/releases/download/v3.22.3/cmake-3.22.3-linux-x86_64.sh\n",
    "        !sudo mkdir /opt/cmake\n",
    "        !sudo sh ./cmake-3.22.3-linux-x86_64.sh --prefix=/opt/cmake \\\n",
    "            --skip-license\n",
    "        %cd /content\n",
    "        !update-alternatives --install /usr/local/bin/cmake cmake \\\n",
    "            /opt/cmake/bin/cmake 20 --force\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-vDIeFnUup2"
   },
   "source": [
    "## AO\n",
    "Setup Acoustic Odometry python package. If this notebook is being executed in\n",
    "[Colab](#colab), the package will be installed from Github. Because of this, a\n",
    "Github [personal access\n",
    "token](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token)\n",
    "will be asked during the installation.\n",
    "\n",
    "If the notebook is not running on Colab and the package is not already\n",
    "installed, installation instructions will be prompted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XZPO4X8roB8k",
    "outputId": "c1fcf943-8933-4af5-89e6-5672e073bd74"
   },
   "outputs": [],
   "source": [
    "if COLAB_RUNTIME:\n",
    "    from getpass import getpass\n",
    "    if not GITHUB_TOKEN:\n",
    "        GITHUB_TOKEN = getpass(\n",
    "            \"Personal access token\\n\"\n",
    "            r\"https://docs.github.com/en/authentication/keeping-your-account-\"\n",
    "            r\"and-data-secure/creating-a-personal-access-token\"+\"\\n\"\n",
    "            )\n",
    "    %pip install git+https://$GITHUB_TOKEN@github.com/AcousticOdometry/AO\n",
    "    try:\n",
    "        import ao\n",
    "    except ImportError:\n",
    "        GITHUB_TOKEN = None\n",
    "        raise\n",
    "else:\n",
    "    try:\n",
    "        import ao\n",
    "    except ImportError:\n",
    "        raise ImportError(\n",
    "            \"Acoustic Odometry python extension is not installed. Check \"\n",
    "            r\"https://github.com/AcousticOdometry/AO#readme\"\n",
    "            \" for detailed instructions.\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JP7gX_G3UrV_"
   },
   "source": [
    "## Other packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "hFV56apJJicf"
   },
   "outputs": [],
   "source": [
    "import ao\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(layers.Layer):\n",
    "\n",
    "    def __init__(self, embed_dim, num_heads, feed_forward_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.att = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "            )\n",
    "        self.ffn = keras.Sequential([\n",
    "            layers.Dense(feed_forward_dim, activation=\"relu\"),\n",
    "            layers.Dense(embed_dim),\n",
    "            ])\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(dropout)\n",
    "        self.dropout2 = layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(keras.Model):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Data folder should be provided as an environment variable. It can be written in\n",
    "an `.env` file in the root of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB_RUNTIME:\n",
    "    # TODO Mount drive and find VAO_Primitive-Experiment\n",
    "    # TODO Otherwise prompt to add shortcut to drive from link\n",
    "    # https://drive.google.com/drive/folders/1I6dq8gJpsrD3C14-WQKD4IFOnkiVuvFX\n",
    "    raise NotImplementedError()\n",
    "else:\n",
    "    DATA_FOLDER = ao.dataset.utils.get_data_folder(env='PRIMITIVE_EXPERIMENT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\esdan\\Desktop\\AO\\venv\\lib\\site-packages\\ao\\dataset\\utils.py:124: UserWarning: Could not parse VAO_2022-03-08_17-11-21 from C:\\Users\\esdan\\OneDrive - keio.jp\\Thesis\\Primitive Experiment\\VAO_2022-03-08_17-11-21, item VAO_2022-03-08_17-11-21 should be composed by one `key` and one `value` separated by a unique underscore but 2 `_` were found.\n",
      "  warn(str(e))\n",
      "c:\\Users\\esdan\\Desktop\\AO\\venv\\lib\\site-packages\\ao\\dataset\\utils.py:124: UserWarning: Could not parse VAO_2022-03-08_17-12-37 from C:\\Users\\esdan\\OneDrive - keio.jp\\Thesis\\Primitive Experiment\\VAO_2022-03-08_17-12-37, item VAO_2022-03-08_17-12-37 should be composed by one `key` and one `value` separated by a unique underscore but 2 `_` were found.\n",
      "  warn(str(e))\n"
     ]
    }
   ],
   "source": [
    "data, naming = ao.dataset.utils.list_data(DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "To specify the output signature you need to provide either the `output_signature` argument or the `output_types` argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\esdan\\Desktop\\AO\\notebooks\\train_model.ipynb Cell 17'\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/train_model.ipynb#ch0000016?line=28'>29</a>\u001b[0m             frame_features \u001b[39m=\u001b[39m extract(frame)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/train_model.ipynb#ch0000016?line=29'>30</a>\u001b[0m             \u001b[39myield\u001b[39;00m (frame_features, motion)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/train_model.ipynb#ch0000016?line=32'>33</a>\u001b[0m audio_ds \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mDataset\u001b[39m.\u001b[39;49mfrom_generator(generate_audio_dataset)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/train_model.ipynb#ch0000016?line=33'>34</a>\u001b[0m \u001b[39mprint\u001b[39m(audio_ds\u001b[39m.\u001b[39mtake(\u001b[39m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\esdan\\Desktop\\AO\\venv\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:548\u001b[0m, in \u001b[0;36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/tensorflow/python/util/deprecation.py?line=539'>540</a>\u001b[0m         _PRINTED_WARNING[(func, arg_name)] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/tensorflow/python/util/deprecation.py?line=540'>541</a>\u001b[0m       logging\u001b[39m.\u001b[39mwarning(\n\u001b[0;32m    <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/tensorflow/python/util/deprecation.py?line=541'>542</a>\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mFrom \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: calling \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m (from \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) with \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is deprecated and will \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/tensorflow/python/util/deprecation.py?line=542'>543</a>\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mbe removed \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mInstructions for updating:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/tensorflow/python/util/deprecation.py?line=545'>546</a>\u001b[0m           \u001b[39m'\u001b[39m\u001b[39min a future version\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m date \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mafter \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m date),\n\u001b[0;32m    <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/tensorflow/python/util/deprecation.py?line=546'>547</a>\u001b[0m           instructions)\n\u001b[1;32m--> <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/tensorflow/python/util/deprecation.py?line=547'>548</a>\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\esdan\\Desktop\\AO\\venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:935\u001b[0m, in \u001b[0;36mDatasetV2.from_generator\u001b[1;34m(generator, output_types, output_shapes, args, output_signature, name)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=932'>933</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=933'>934</a>\u001b[0m   \u001b[39mif\u001b[39;00m output_types \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=934'>935</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTo specify the output signature you need to provide \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=935'>936</a>\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39meither the `output_signature` argument or the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=936'>937</a>\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39m`output_types` argument.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=938'>939</a>\u001b[0m \u001b[39mif\u001b[39;00m output_signature \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=939'>940</a>\u001b[0m   \u001b[39mif\u001b[39;00m output_shapes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: To specify the output signature you need to provide either the `output_signature` argument or the `output_types` argument."
     ]
    }
   ],
   "source": [
    "FRAME_SAMPLES = 1024\n",
    "NUM_FEATURES = 64\n",
    "\n",
    "audio_sample, samplerate = ao.io.wave_read(list(data.keys())[0] / 'audio0.wav')\n",
    "extract = ao.extractor.GammatoneFilterbank(\n",
    "    FRAME_SAMPLES, NUM_FEATURES, samplerate\n",
    "    )\n",
    "\n",
    "\n",
    "def generate_audio_dataset(\n",
    "        data,\n",
    "        frame_samples: int = FRAME_SAMPLES,\n",
    "        num_features: int = NUM_FEATURES\n",
    "    ):\n",
    "    for folder, parameters in data:\n",
    "        audio_path = folder / 'audio0crop.wav'\n",
    "        audio, _samplerate = ao.io.wave_read(audio_path)\n",
    "        assert _samplerate == samplerate, \"Samplerate mismatch\"\n",
    "        num_frames = tf.math.ceil(audio.size / frame_samples)\n",
    "        vx = parameters['contact'] * parmeters['w'] * 0.10  # 10 cm radius\n",
    "        motion = (vx, 0)  # No angular rotation\n",
    "        # Pad the data to be a multiple of the frame size\n",
    "        audio = np.append(\n",
    "            audio, np.zeros(num_frames * frame_samples - audio.size)\n",
    "            )\n",
    "        for frame_num in range(num_frames):\n",
    "            frame = audio[frame_num * frame_samples:(frame_num + 1) *\n",
    "                          frame_samples]\n",
    "            frame_features = extract(frame)\n",
    "            yield (frame_features, motion)\n",
    "\n",
    "\n",
    "audio_ds = tf.data.Dataset.from_generator(generate_audio_dataset)\n",
    "print(audio_ds.take(1))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d21f40ac55f28466c21dd799498b12929e39799c097f46cd49280349550824b8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
