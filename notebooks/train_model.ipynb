{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TRorKX0aJrmb"
   },
   "source": [
    "This notebook is part of Andreu's (esdandreu@gmail.com) Master Thesis work at\n",
    "Keio University.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/AcousticOdometry/AO/blob/main/notebooks/train_model.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C2Q8wXiqTp00"
   },
   "source": [
    "# Setup\n",
    "\n",
    "This section will take care of installing the necessary packages as well as\n",
    "configuring some environment variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colab\n",
    "\n",
    "Assess wether the notebook is being executed in [Google\n",
    "Colab](https://colab.research.google.com/) and if so, set up the software\n",
    "needed in Colab runtime.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Mxqlh9G3n3sF"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "try:\n",
    "    from google import colab\n",
    "    COLAB_RUNTIME = True\n",
    "    %pip install torchinfo\n",
    "    colab.drive.mount('/content/drive')\n",
    "except ImportError:\n",
    "    COLAB_RUNTIME = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JP7gX_G3UrV_"
   },
   "source": [
    "## Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hFV56apJJicf"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchinfo import summary\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-vDIeFnUup2"
   },
   "source": [
    "### AO\n",
    "\n",
    "Setup Acoustic Odometry python package. If this notebook is being executed in\n",
    "[Colab](#colab), the package will be installed from Github. Because of this, a\n",
    "Github [personal access\n",
    "token](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token)\n",
    "is needed for the installation.\n",
    "\n",
    "If the notebook is not running on Colab and the package is not already\n",
    "installed, installation instructions will be prompted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XZPO4X8roB8k",
    "outputId": "c1fcf943-8933-4af5-89e6-5672e073bd74"
   },
   "outputs": [],
   "source": [
    "if COLAB_RUNTIME:\n",
    "    import subprocess\n",
    "    import requests\n",
    "    import sys\n",
    "    import os\n",
    "    #@markdown Use a [GitHub Personal Access Token](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token)\n",
    "    GITHUB_TOKEN = ''  #@param {type:\"string\"}\n",
    "    auth = requests.auth.HTTPBasicAuth('', GITHUB_TOKEN)\n",
    "    response = requests.get(\n",
    "        \"https://api.github.com/repos/AcousticOdometry/AO/releases/latest\",\n",
    "        auth=auth\n",
    "        )\n",
    "    try:\n",
    "        response.raise_for_status()\n",
    "    except requests.HTTPError as e:\n",
    "        raise RuntimeError(\n",
    "            'Check GITHUB_TOKEN is a Personal Access Token with repo access'\n",
    "            )\n",
    "    headers = {'Accept': 'application/octet-stream'}\n",
    "    for asset in response.json()['assets']:\n",
    "        r = requests.get(\n",
    "            asset['url'], auth=auth, allow_redirects=True, headers=headers\n",
    "            )\n",
    "        r.raise_for_status()\n",
    "        wheel_name = asset['name']\n",
    "        with open(wheel_name, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "        try:\n",
    "            result = subprocess.check_output([\n",
    "                sys.executable, '-m', 'pip', 'install', wheel_name\n",
    "                ])\n",
    "            print(f'Installed {wheel_name}')\n",
    "            break\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            pass\n",
    "        finally:\n",
    "            os.remove(wheel_name)\n",
    "    import ao\n",
    "else:\n",
    "    try:\n",
    "        import ao\n",
    "    except ImportError:\n",
    "        raise ImportError(\n",
    "            \"Acoustic Odometry python extension is not installed. Check \"\n",
    "            r\"https://github.com/AcousticOdometry/AO#readme\"\n",
    "            \" for detailed instructions.\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_folder = Path().parent / 'logs'\n",
    "logging_folder.mkdir(exist_ok=True)\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setLevel(logging.INFO)\n",
    "logging.basicConfig(\n",
    "    format=\"[%(levelname)s] %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\n",
    "            logging_folder / datetime.now().strftime('%Y%m%d_%H%M%S.log')\n",
    "            ),\n",
    "        stream_handler,\n",
    "        ],\n",
    "    level=logging.DEBUG\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import abstractmethod\n",
    "\n",
    "class AcousticOdometryModel(nn.Module):\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "# Reset the subclasses to allow changes without restarting the kernel\n",
    "for subclass in AcousticOdometryModel.__subclasses__():\n",
    "    del subclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNet(AcousticOdometryModel):\n",
    "    def __init__(self, classes: int):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(210816, 512)\n",
    "        self.fc2 = nn.Linear(512, classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        #x = x.view(x.size(0), -1)\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.log_softmax(x,dim=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[__main__.CNNet]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AcousticOdometryModel.__subclasses__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB_RUNTIME:\n",
    "    # @markdown Check where is the experiment folder situated in your drive folder.\n",
    "    # @markdown Remember that if you have been shared the folder, you can\n",
    "    # @markdown [add a shortcut to your drive](https://support.google.com/drive/answer/9700156?hl=en&co=GENIE.Platform%3DDesktop)\n",
    "    # @markdown in order to make it available in google colab.\n",
    "    experiment = \"/content/drive/MyDrive/VAO_WheelTestBed-Experiment-1\"  #@param {type:\"string\"}\n",
    "    EXPERIMENT_FOLDER = Path(experiment)\n",
    "    if not EXPERIMENT_FOLDER.is_dir():\n",
    "        raise RuntimeError(f'Invalid experiment folder {EXPERIMENT_FOLDER}')\n",
    "else:\n",
    "    EXPERIMENT_FOLDER = ao.dataset.utils.get_folder(\n",
    "        env='WHEELTESTBED_EXPERIMENT1'\n",
    "        )\n",
    "DATASETS_FOLDER = EXPERIMENT_FOLDER / 'datasets'\n",
    "MODELS_FOLDER = EXPERIMENT_FOLDER / 'models'\n",
    "MODELS_FOLDER.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Using cuda device\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "logging.info('Using {} device'.format(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(\n",
    "    dataset_folder: Path,\n",
    "    train_split: float = 0.8,\n",
    "    batch_size: int = 15,\n",
    "    ) -> Tuple[Dict[str, torch.utils.data.DataLoader], Dict[str, int]]:\n",
    "    dataset = datasets.ImageFolder(\n",
    "        root=dataset_folder,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.ToTensor()\n",
    "            ])\n",
    "        )\n",
    "    train_size = int(train_split * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    loaders = {}\n",
    "    for split, name in zip(\n",
    "        torch.utils.data.random_split(dataset, [train_size, test_size]),\n",
    "        ['train', 'test']\n",
    "        ):\n",
    "        loaders[name] = torch.utils.data.DataLoader(\n",
    "            split,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=2 if DEVICE == 'cuda' else 1,\n",
    "            shuffle=True,\n",
    "            pin_memory=True if DEVICE == 'cuda' else False,\n",
    "            )\n",
    "        logging.info(\n",
    "            f'{name} set: {len(split)} samples, {len(loaders[name])} batches'\n",
    "            )\n",
    "    return loaders, dataset.class_to_idx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "    model: torch.nn.Module,\n",
    "    cost_function: torch.nn.modules.loss._Loss,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    ):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    # TODO use tqdm\n",
    "    for batch_n, (X, Y) in enumerate(dataloader):\n",
    "        X, Y = X.to(DEVICE), Y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(X)\n",
    "        loss = cost_function(prediction, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_n % 100 == 0:\n",
    "            loss, current = loss.item(), batch_n * len(X)\n",
    "            logging.debug(f'loss: {loss:>7f}  [{current:>5d}/{size:>5d}]')\n",
    "\n",
    "\n",
    "def test(\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "    model: torch.nn.Module,\n",
    "    cost_function: torch.nn.modules.loss._Loss,\n",
    "    ):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, Y in dataloader:\n",
    "            X, Y = X.to(DEVICE), Y.to(DEVICE)\n",
    "            pred = model(X)\n",
    "\n",
    "            test_loss += cost_function(pred, Y).item()\n",
    "            correct += (pred.argmax(1) == Y).type(torch.float).sum().item()\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    logging.info(f'acc: {(100*correct):>0.1f}%, avg loss: {test_loss:>8f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    dataset_folder: Path,\n",
    "    model_class: AcousticOdometryModel,\n",
    "    epochs: int = 15,\n",
    "    cost_function: torch.nn.modules.loss._Loss = torch.nn.CrossEntropyLoss(),\n",
    "    optimizer_class: torch.optim.Optimizer = torch.optim.Adam,\n",
    "    optimizer_options: dict = {'lr': 0.001},\n",
    "    ):\n",
    "    loaders, class_to_idx = load_dataset(dataset_folder)\n",
    "    # ! A bit sketchy, in the future the classes should be fixed\n",
    "    model = model_class(classes=len(class_to_idx)).to(DEVICE)\n",
    "    optimizer = optimizer_class(model.parameters(), **optimizer_options)\n",
    "    for t in range(epochs):\n",
    "        logging.info(f'Epoch {t}')\n",
    "        train_epoch(loaders['train'], model, cost_function, optimizer)\n",
    "        test(loaders['test'], model, cost_function)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] train set: 32158 samples, 2144 batches\n",
      "[INFO] test set: 8040 samples, 536 batches\n",
      "[INFO] Epoch 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (15x210816 and 105408x300)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\esdan\\Desktop\\AO\\notebooks\\train_model.ipynb Cell 23'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/train_model.ipynb#ch0000046?line=0'>1</a>\u001b[0m dataset_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39minitial_cnn_samples\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/train_model.ipynb#ch0000046?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m train(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/train_model.ipynb#ch0000046?line=2'>3</a>\u001b[0m     dataset_folder\u001b[39m=\u001b[39;49mDATASETS_FOLDER \u001b[39m/\u001b[39;49m dataset_name,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/train_model.ipynb#ch0000046?line=3'>4</a>\u001b[0m     model_class\u001b[39m=\u001b[39;49mCNNet,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/train_model.ipynb#ch0000046?line=4'>5</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m15\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/train_model.ipynb#ch0000046?line=5'>6</a>\u001b[0m     )\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/train_model.ipynb#ch0000046?line=6'>7</a>\u001b[0m torch\u001b[39m.\u001b[39msave(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/train_model.ipynb#ch0000046?line=7'>8</a>\u001b[0m     model, MODELS_FOLDER \u001b[39m/\u001b[39m (\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/train_model.ipynb#ch0000046?line=8'>9</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mname_\u001b[39m\u001b[39m{\u001b[39;00mdataset_name\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m;\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/train_model.ipynb#ch0000046?line=9'>10</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mdatetime\u001b[39m.\u001b[39mnow()\u001b[39m.\u001b[39mstrftime(\u001b[39m'\u001b[39m\u001b[39mdate_\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm-\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m;time_\u001b[39m\u001b[39m%\u001b[39m\u001b[39mH-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mM-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mS\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m.pt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/train_model.ipynb#ch0000046?line=10'>11</a>\u001b[0m         )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/train_model.ipynb#ch0000046?line=11'>12</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/train_model.ipynb#ch0000046?line=12'>13</a>\u001b[0m summary(model, input_size\u001b[39m=\u001b[39m(\u001b[39m15\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m256\u001b[39m, \u001b[39m120\u001b[39m))\n",
      "\u001b[1;32mc:\\Users\\esdan\\Desktop\\AO\\notebooks\\train_model.ipynb Cell 22'\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(dataset_folder, model_class, epochs, cost_function, optimizer_class, optimizer_options)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/train_model.ipynb#ch0000022?line=12'>13</a>\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/train_model.ipynb#ch0000022?line=13'>14</a>\u001b[0m     logging\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mt\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/train_model.ipynb#ch0000022?line=14'>15</a>\u001b[0m     train_epoch(loaders[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m], model, cost_function, optimizer)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/train_model.ipynb#ch0000022?line=15'>16</a>\u001b[0m     test(loaders[\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m], model, cost_function)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/train_model.ipynb#ch0000022?line=16'>17</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "\u001b[1;32mc:\\Users\\esdan\\Desktop\\AO\\notebooks\\train_model.ipynb Cell 21'\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(dataloader, model, cost_function, optimizer)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/train_model.ipynb#ch0000021?line=10'>11</a>\u001b[0m X, Y \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(DEVICE), Y\u001b[39m.\u001b[39mto(DEVICE)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/train_model.ipynb#ch0000021?line=11'>12</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/train_model.ipynb#ch0000021?line=12'>13</a>\u001b[0m prediction \u001b[39m=\u001b[39m model(X)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/train_model.ipynb#ch0000021?line=13'>14</a>\u001b[0m loss \u001b[39m=\u001b[39m cost_function(prediction, Y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/train_model.ipynb#ch0000021?line=14'>15</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\esdan\\Desktop\\AO\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\esdan\\Desktop\\AO\\notebooks\\train_model.ipynb Cell 14'\u001b[0m in \u001b[0;36mCNNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/train_model.ipynb#ch0000039?line=14'>15</a>\u001b[0m \u001b[39m#x = x.view(x.size(0), -1)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/train_model.ipynb#ch0000039?line=15'>16</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflatten(x)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/train_model.ipynb#ch0000039?line=16'>17</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc1(x))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/train_model.ipynb#ch0000039?line=17'>18</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mdropout(x, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/esdan/Desktop/AO/notebooks/train_model.ipynb#ch0000039?line=18'>19</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2(x))\n",
      "File \u001b[1;32mc:\\Users\\esdan\\Desktop\\AO\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\esdan\\Desktop\\AO\\venv\\lib\\site-packages\\torch\\nn\\modules\\linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/torch/nn/modules/linear.py?line=101'>102</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> <a href='file:///c%3A/Users/esdan/Desktop/AO/venv/lib/site-packages/torch/nn/modules/linear.py?line=102'>103</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (15x210816 and 105408x300)"
     ]
    }
   ],
   "source": [
    "dataset_name = 'initial_cnn_samples'\n",
    "model = train(\n",
    "    dataset_folder=DATASETS_FOLDER / dataset_name,\n",
    "    model_class=CNNet,\n",
    "    epochs=15,\n",
    "    )\n",
    "torch.save(\n",
    "    model, MODELS_FOLDER / (\n",
    "        f\"name_{dataset_name.replace('_','-')};\" +\n",
    "        f\"{datetime.now().strftime('date_%Y-%m-%d;time_%H-%M-%S')}.pt\"\n",
    "        )\n",
    "    )\n",
    "summary(model, input_size=(15, 1, 256, 120))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b8749b76b3be249eef7e116ab90f03825c0416a2284545ab24c0f7f41fa4add3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
