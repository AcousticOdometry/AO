{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TRorKX0aJrmb"
   },
   "source": [
    "This notebook is part of Andreu's (esdandreu@gmail.com) Master Thesis work at\n",
    "Keio University.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/AcousticOdometry/AO/blob/main/notebooks/train_model.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C2Q8wXiqTp00"
   },
   "source": [
    "# Setup\n",
    "This section will take care of installing the necessary packages as well as\n",
    "configuring some environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLAB_RUNTIME = False\n",
    "GITHUB_TOKEN = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colab\n",
    "Assess wether the notebook is being executed in [Google\n",
    "Colab](https://colab.research.google.com/) and if so, set up the software\n",
    "needed in Colab runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Mxqlh9G3n3sF"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "try:\n",
    "    import colab\n",
    "    COLAB_RUNTIME = True\n",
    "    # Check CMake >= 3.21\n",
    "    v_str, *_ = !cmake --version\n",
    "    if 'command not found' in v_str:\n",
    "        major, minor = (0, 0)\n",
    "    else:\n",
    "        major, minor, _ = (int(x) for x in v_str.split(' ')[-1].split('.'))\n",
    "    if major < 3 or minor < 21:\n",
    "        # https://cmake.org/download/\n",
    "        %cd /tmp\n",
    "        !wget https://github.com/Kitware/CMake/releases/download/v3.22.3/cmake-3.22.3-linux-x86_64.sh\n",
    "        !sudo mkdir /opt/cmake\n",
    "        !sudo sh ./cmake-3.22.3-linux-x86_64.sh --prefix=/opt/cmake \\\n",
    "            --skip-license\n",
    "        %cd /content\n",
    "        !update-alternatives --install /usr/local/bin/cmake cmake \\\n",
    "            /opt/cmake/bin/cmake 20 --force\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-vDIeFnUup2"
   },
   "source": [
    "## AO\n",
    "Setup Acoustic Odometry python package. If this notebook is being executed in\n",
    "[Colab](#colab), the package will be installed from Github. Because of this, a\n",
    "Github [personal access\n",
    "token](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token)\n",
    "will be asked during the installation.\n",
    "\n",
    "If the notebook is not running on Colab and the package is not already\n",
    "installed, installation instructions will be prompted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XZPO4X8roB8k",
    "outputId": "c1fcf943-8933-4af5-89e6-5672e073bd74"
   },
   "outputs": [],
   "source": [
    "if COLAB_RUNTIME:\n",
    "    from getpass import getpass\n",
    "    if not GITHUB_TOKEN:\n",
    "        GITHUB_TOKEN = getpass(\n",
    "            \"Personal access token\\n\"\n",
    "            r\"https://docs.github.com/en/authentication/keeping-your-account-\"\n",
    "            r\"and-data-secure/creating-a-personal-access-token\"+\"\\n\"\n",
    "            )\n",
    "    %pip install git+https://$GITHUB_TOKEN@github.com/AcousticOdometry/AO\n",
    "    try:\n",
    "        import ao\n",
    "    except ImportError:\n",
    "        GITHUB_TOKEN = None\n",
    "        raise\n",
    "else:\n",
    "    try:\n",
    "        import ao\n",
    "    except ImportError:\n",
    "        raise ImportError(\n",
    "            \"Acoustic Odometry python extension is not installed. Check \"\n",
    "            r\"https://github.com/AcousticOdometry/AO#readme\"\n",
    "            \" for detailed instructions.\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JP7gX_G3UrV_"
   },
   "source": [
    "## Other packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hFV56apJJicf"
   },
   "outputs": [],
   "source": [
    "import ao\n",
    "import logging\n",
    "\n",
    "from typing import Dict\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchinfo import summary\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_folder = Path().parent / 'logs'\n",
    "logging_folder.mkdir(exist_ok=True)\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setLevel(logging.INFO)\n",
    "logging.basicConfig(\n",
    "    format=\"[%(levelname)s] %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\n",
    "            logging_folder / datetime.now().strftime('%Y%m%d_%H%M%S.log')\n",
    "            ),\n",
    "        stream_handler,\n",
    "        ],\n",
    "    level=logging.DEBUG\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB_RUNTIME:\n",
    "    # TODO Mount drive and find VAO_Primitive-Experiment\n",
    "    # TODO Otherwise prompt to add shortcut to drive from link\n",
    "    # https://drive.google.com/drive/folders/1I6dq8gJpsrD3C14-WQKD4IFOnkiVuvFX\n",
    "    raise NotImplementedError()\n",
    "else:\n",
    "    EXPERIMENT_FOLDER = ao.dataset.utils.get_folder(\n",
    "        env='WHEELTESTBED_EXPERIMENT'\n",
    "        )\n",
    "    DATASETS_FOLDER = EXPERIMENT_FOLDER / 'datasets'\n",
    "    MODELS_FOLDER = Path().parent.parent / 'models'\n",
    "    MODELS_FOLDER.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(\n",
    "    dataset_folder: Path,\n",
    "    train_split: float = 0.8,\n",
    "    batch_size: int = 15,\n",
    "    validation_dataset_folder: Path = None,\n",
    "    ) -> Dict[str, torch.utils.data.DataLoader]:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'000': 0, '001': 1, '002': 2, '003': 3, '004': 4, '005': 5, '006': 6}\n"
     ]
    }
   ],
   "source": [
    "dataset_folder = DATASETS_FOLDER / 'initial_cnn_samples'\n",
    "dataset = datasets.ImageFolder(\n",
    "    root=dataset_folder, transform=transforms.Compose([transforms.ToTensor()])\n",
    "    )\n",
    "print(dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 32158\n",
      "Testing size: 8040\n"
     ]
    }
   ],
   "source": [
    "#split data to test and train\n",
    "#use 80% to train\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    dataset, [train_size, test_size]\n",
    "    )\n",
    "\n",
    "print(\"Training size:\", len(train_dataset))\n",
    "print(\"Testing size:\", len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=15,\n",
    "    num_workers=2,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=15,\n",
    "    num_workers=2,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(105408, 300)\n",
    "        self.fc2 = nn.Linear(300, len(dataset.classes))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        #x = x.view(x.size(0), -1)\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.log_softmax(x,dim=1)  \n",
    "\n",
    "model = CNNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function used to determine best parameters\n",
    "cost = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# used to create optimal parameters\n",
    "learning_rate = 0.0001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "def test(dataloader, model):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, Y in dataloader:\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "            pred = model(X)\n",
    "\n",
    "            test_loss += cost(pred, Y).item()\n",
    "            correct += (pred.argmax(1) == Y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    logging.info(f'acc: {(100*correct):>0.1f}%, avg loss: {test_loss:>8f}')\n",
    "\n",
    "\n",
    "def train(dataloader, model, loss, optimizer):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    # TODO use tqdm\n",
    "    for batch_n, (X, Y) in enumerate(dataloader):\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X)\n",
    "        loss = cost(pred, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_n % 100 == 0:\n",
    "            loss, current = loss.item(), batch_n * len(X)\n",
    "            logging.debug(f'loss: {loss:>7f}  [{current:>5d}/{size:>5d}]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(dataset, model, epochs, validation_dataset=None):\n",
    "    model.train()\n",
    "    # size = len(dataloader.dataset)\n",
    "    # TODO dataset into dataloaders\n",
    "    # TODO epochs\n",
    "    # TODO use tqdm\n",
    "    for batch_n, (X, Y) in enumerate(dataloader):\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X)\n",
    "        loss = cost(pred, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_n % 100 == 0:\n",
    "            loss, current = loss.item(), batch_n * len(X)\n",
    "            logging.debug(f'loss: {loss:>7f}  [{current:>5d}/{size:>5d}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Epoch 0\n",
      "[INFO] \n",
      "Test Error:\n",
      "acc: 66.2%, avg loss: 0.063582\n",
      "\n",
      "[INFO] Epoch 1\n",
      "[INFO] \n",
      "Test Error:\n",
      "acc: 75.7%, avg loss: 0.049014\n",
      "\n",
      "[INFO] Epoch 2\n",
      "[INFO] \n",
      "Test Error:\n",
      "acc: 81.4%, avg loss: 0.037889\n",
      "\n",
      "[INFO] Epoch 3\n",
      "[INFO] \n",
      "Test Error:\n",
      "acc: 84.1%, avg loss: 0.032734\n",
      "\n",
      "[INFO] Epoch 4\n",
      "[INFO] \n",
      "Test Error:\n",
      "acc: 83.7%, avg loss: 0.031658\n",
      "\n",
      "[INFO] Epoch 5\n",
      "[INFO] \n",
      "Test Error:\n",
      "acc: 86.5%, avg loss: 0.027330\n",
      "\n",
      "[INFO] Epoch 6\n",
      "[INFO] \n",
      "Test Error:\n",
      "acc: 87.2%, avg loss: 0.025854\n",
      "\n",
      "[INFO] Epoch 7\n",
      "[INFO] \n",
      "Test Error:\n",
      "acc: 88.0%, avg loss: 0.024643\n",
      "\n",
      "[INFO] Epoch 8\n",
      "[INFO] \n",
      "Test Error:\n",
      "acc: 88.9%, avg loss: 0.022725\n",
      "\n",
      "[INFO] Epoch 9\n",
      "[INFO] \n",
      "Test Error:\n",
      "acc: 89.3%, avg loss: 0.022265\n",
      "\n",
      "[INFO] Epoch 10\n",
      "[INFO] \n",
      "Test Error:\n",
      "acc: 89.6%, avg loss: 0.021928\n",
      "\n",
      "[INFO] Epoch 11\n",
      "[INFO] \n",
      "Test Error:\n",
      "acc: 89.9%, avg loss: 0.021545\n",
      "\n",
      "[INFO] Epoch 12\n",
      "[INFO] \n",
      "Test Error:\n",
      "acc: 90.4%, avg loss: 0.020569\n",
      "\n",
      "[INFO] Epoch 13\n",
      "[INFO] \n",
      "Test Error:\n",
      "acc: 90.4%, avg loss: 0.020617\n",
      "\n",
      "[INFO] Epoch 14\n",
      "[INFO] \n",
      "Test Error:\n",
      "acc: 90.1%, avg loss: 0.020479\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "\n",
    "for t in range(epochs):\n",
    "    logging.info(f'Epoch {t}')\n",
    "    train(train_dataloader, model, cost, optimizer)\n",
    "    test(test_dataloader, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, input_size=(15, 3, 256, 120))\n",
    "torch.save(model, MODELS_FOLDER / 'initial_cnn_samples.pt')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b8749b76b3be249eef7e116ab90f03825c0416a2284545ab24c0f7f41fa4add3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
